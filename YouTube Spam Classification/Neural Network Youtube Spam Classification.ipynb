{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b2690-9973-4add-ae74-da2a8e11cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "import numpy as np \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, Activation \n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba53f8-eb3f-46d4-98d0-34013d46792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([pd.read_csv(\"Youtube Spam Classification\\Youtube01-Psy.csv\"), \n",
    "               pd.read_csv(\"Youtube Spam Classification\\Youtube02-KatyPerry.csv\"), \n",
    "               pd.read_csv(\"Youtube Spam Classification\\Youtube03-LMFAO.csv\"),\n",
    "               pd.read_csv(\"Youtube Spam Classification\\Youtube04-Eminem.csv\"), \n",
    "               pd.read_csv(\"Youtube Spam Classification\\Youtube05-Shakira.csv\")]) \n",
    "d = d.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c2b1e-0ede-49fa-b6ef-219a80d19d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "splits = kfold.split(d, d['CLASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99c21a-0cc3-40a0-a51e-0fb6712992b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in splits:\n",
    "    print('Split')\n",
    "    print(np.shape(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53311c1-e5e6-453e-8e4c-c681e27e6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(train_idx, test_idx): \n",
    "    train_content = d['CONTENT'].iloc[train_idx] \n",
    "    test_content = d['CONTENT'].iloc[test_idx]\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=2000)\n",
    "    \n",
    "    # Learn the training words (not the testing words!) \n",
    "    tokenizer.fit_on_texts(train_content) \n",
    "    \n",
    "    #options for mode: binary, freq, tfidf \n",
    "    d_train_inputs = tokenizer.texts_to_matrix(train_content, mode='tfidf') \n",
    "    d_test_inputs = tokenizer.texts_to_matrix(test_content, mode='tfidf') \n",
    "    \n",
    "    # divide tfidf by max \n",
    "    d_train_inputs = d_train_inputs/np.amax(np.absolute(d_train_inputs)) \n",
    "    d_test_inputs = d_test_inputs/np.amax(np.absolute(d_test_inputs))\n",
    "\n",
    "    # subtract mean, to get values between -1 and 1 \n",
    "    d_train_inputs = d_train_inputs - np.mean(d_train_inputs) \n",
    "    d_test_inputs = d_test_inputs - np.mean(d_test_inputs)\n",
    "\n",
    "    #one -hot encoding\n",
    "    d_train_outputs = to_categorical(d['CLASS'].iloc[train_idx])\n",
    "    d_test_outputs = to_categorical(d['CLASS'].iloc[test_idx])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(2000,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adamax',\n",
    "                 metrics=['accuracy'])\n",
    "    model.fit(d_train_inputs, d_train_outputs, epochs=10, batch_size=16)\n",
    "\n",
    "    scores = model.evaluate(d_test_inputs, d_test_outputs) \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100)) \n",
    "    \n",
    "    # ðŸš€ Return the model and tokenizer\n",
    "    return scores, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0633b8-e659-48cd-b89b-d7fe4ea61c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "splits = kfold.split(d, d['CLASS'])\n",
    "cvscores = []\n",
    "\n",
    "final_model = None\n",
    "final_tokenizer = None\n",
    "\n",
    "for train_idx, test_idx in splits:\n",
    "    scores, model, tokenizer = train_and_test(train_idx, test_idx)\n",
    "    cvscores.append(scores[1]*100)\n",
    "\n",
    "    # Save the last model and tokenizer\n",
    "    final_model = model\n",
    "    final_tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45d2aa-170a-4722-abb4-9daaa34b04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9f7b1-9847-42bb-ab0f-2ef366b8a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test(text):\n",
    "    # Minimal preprocessing (just to match the model's expectations)\n",
    "    processed_input = tokenizer.texts_to_matrix([text], mode='tfidf')\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(processed_input)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    \n",
    "    # Map the output\n",
    "    label_mapping = {0: \"Not Spam\", 1: \"Spam\"}\n",
    "    print(f\"Prediction: {label_mapping[predicted_class]} ({prediction[0][predicted_class]*100:.2f}%)\")\n",
    "\n",
    "# Test with a spam message\n",
    "simple_test(\"The song is good, but do subscribe my channel coz its lot more better\")\n",
    "\n",
    "# Test with a normal message\n",
    "simple_test(\"the song is really great. I loved it! kind of similar to those of my channel's videos\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
